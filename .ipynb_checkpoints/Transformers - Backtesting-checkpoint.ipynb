{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b6bf7d",
   "metadata": {},
   "source": [
    "# <center> <font color=#102C54> <i> Transformers - Trading </font> </center> </i>\n",
    "\n",
    "<img style=\"float: left;;\" src='https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg' width=\"80\" height=\"160\"/></a>\n",
    "    \n",
    "<i><center> **Trading Microstructure**  \n",
    "    <center> Claudia Valeria Chimal Parra \n",
    "    <center> Paulo Cesar Ayala Gutiérrez\n",
    "    <center> Juan Carlos Gutiérrez Valdivia\n",
    "    <center> Oscar Leonardo Vaca González\n",
    "    <center> Arturo Espinosa Carabez\n",
    "        \n",
    "   <center> May 5th, 2024 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5491c4c3",
   "metadata": {},
   "source": [
    "# Classification With Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d4522b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad424941",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./data/aapl_5m_train.csv\").dropna()\n",
    "data_test = pd.read_csv(\"./data/aapl_5m_test.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b24d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gmtoffset</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1609770600</td>\n",
       "      <td>0</td>\n",
       "      <td>04/01/2021 14:30</td>\n",
       "      <td>133.570007</td>\n",
       "      <td>133.611602</td>\n",
       "      <td>132.389999</td>\n",
       "      <td>132.809997</td>\n",
       "      <td>6624663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1609770900</td>\n",
       "      <td>0</td>\n",
       "      <td>04/01/2021 14:35</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>132.750000</td>\n",
       "      <td>131.809997</td>\n",
       "      <td>131.889999</td>\n",
       "      <td>2541553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1609771200</td>\n",
       "      <td>0</td>\n",
       "      <td>04/01/2021 14:40</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.339996</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.059997</td>\n",
       "      <td>2492415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1609771500</td>\n",
       "      <td>0</td>\n",
       "      <td>04/01/2021 14:45</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>131.899993</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>1859131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1609771800</td>\n",
       "      <td>0</td>\n",
       "      <td>04/01/2021 14:50</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.018096</td>\n",
       "      <td>131.520004</td>\n",
       "      <td>131.589996</td>\n",
       "      <td>1780105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  Gmtoffset          Datetime        Open        High  \\\n",
       "0  1609770600          0  04/01/2021 14:30  133.570007  133.611602   \n",
       "1  1609770900          0  04/01/2021 14:35  132.750000  132.750000   \n",
       "2  1609771200          0  04/01/2021 14:40  131.500000  132.339996   \n",
       "3  1609771500          0  04/01/2021 14:45  132.000000  132.250000   \n",
       "4  1609771800          0  04/01/2021 14:50  132.000000  132.018096   \n",
       "\n",
       "          Low       Close     Volume  \n",
       "0  132.389999  132.809997  6624663.0  \n",
       "1  131.809997  131.889999  2541553.0  \n",
       "2  131.500000  132.059997  2492415.0  \n",
       "3  131.899993  132.250000  1859131.0  \n",
       "4  131.520004  131.589996  1780105.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ac8c2",
   "metadata": {},
   "source": [
    "## Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45cc2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = data_train.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].mean()\n",
    "train_std = data_train.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]].std()\n",
    "\n",
    "norm_data_train = (data_train.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]] - train_mean) / train_std\n",
    "norm_data_test = (data_test.loc[:, [\"Open\", \"High\", \"Low\", \"Close\"]] - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de9f2a",
   "metadata": {},
   "source": [
    "## Generating our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51681107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI configurations\n",
    "rsi_params = {\n",
    "    'window': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]\n",
    "}\n",
    "\n",
    "# WMA (Weighted Moving Average) configurations\n",
    "wma_params = {\n",
    "    'window': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]\n",
    "}\n",
    "\n",
    "# MACD configurations\n",
    "macd_params = {\n",
    "    'fast_period': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
    "    'slow_period': [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    'signal_period': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "}\n",
    "\n",
    "# Bollinger Bands configurations\n",
    "boll_params = {\n",
    "    'window': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34],\n",
    "    'window_dev': [2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf982c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "def normalize(data, column_name):\n",
    "    return (data[column_name] - data[column_name].mean()) / data[column_name].std()\n",
    "\n",
    "for i in range(15):  # Cambia el rango según el número de configuraciones que desees procesar\n",
    "    # RSI\n",
    "    data_train[f'rsi_{i}'] = ta.momentum.RSIIndicator(data_train['Close'], window=rsi_params['window'][i]).rsi()\n",
    "    data_test[f'rsi_{i}'] = ta.momentum.RSIIndicator(data_test['Close'], window=rsi_params['window'][i]).rsi()\n",
    "\n",
    "    # WMA\n",
    "    data_train[f'wma_{i}'] = ta.trend.WMAIndicator(data_train['Close'], window=wma_params['window'][i]).wma()\n",
    "    data_test[f'wma_{i}'] = ta.trend.WMAIndicator(data_test['Close'], window=wma_params['window'][i]).wma()\n",
    "\n",
    "    # MACD\n",
    "    macd = ta.trend.MACD(data_train['Close'], window_fast=macd_params['fast_period'][i], window_slow=macd_params['slow_period'][i], window_sign=macd_params['signal_period'][i])\n",
    "    data_train[f'macd_{i}'] = macd.macd()\n",
    "    data_test[f'macd_{i}'] = ta.trend.MACD(data_test['Close'], window_fast=macd_params['fast_period'][i], window_slow=macd_params['slow_period'][i], window_sign=macd_params['signal_period'][i]).macd()\n",
    "\n",
    "    # Bollinger Bands\n",
    "    bollinger = ta.volatility.BollingerBands(data_train['Close'], window=boll_params['window'][i], window_dev=boll_params['window_dev'][i])\n",
    "    data_train[f'bollinger_mavg_{i}'] = bollinger.bollinger_mavg()\n",
    "    data_train[f'bollinger_hband_{i}'] = bollinger.bollinger_hband()\n",
    "    data_train[f'bollinger_lband_{i}'] = bollinger.bollinger_lband()\n",
    "\n",
    "    bollinger_test = ta.volatility.BollingerBands(data_test['Close'], window=boll_params['window'][i], window_dev=boll_params['window_dev'][i])\n",
    "    data_test[f'bollinger_mavg_{i}'] = bollinger_test.bollinger_mavg()\n",
    "    data_test[f'bollinger_hband_{i}'] = bollinger_test.bollinger_hband()\n",
    "    data_test[f'bollinger_lband_{i}'] = bollinger_test.bollinger_lband()\n",
    "\n",
    "    # Normalize each new indicator and concatenate\n",
    "    for col in [f'rsi_{i}', f'wma_{i}', f'macd_{i}', f'bollinger_mavg_{i}', f'bollinger_hband_{i}', f'bollinger_lband_{i}']:\n",
    "        data_train[col] = normalize(data_train, col)\n",
    "        data_test[col] = normalize(data_test, col)\n",
    "        norm_data_train = pd.concat([norm_data_train, data_train[col]], axis=1)\n",
    "        norm_data_test = pd.concat([norm_data_test, data_test[col]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eb4ed7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>rsi_0</th>\n",
       "      <th>wma_0</th>\n",
       "      <th>macd_0</th>\n",
       "      <th>bollinger_mavg_0</th>\n",
       "      <th>bollinger_hband_0</th>\n",
       "      <th>bollinger_lband_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.923792</td>\n",
       "      <td>-0.931312</td>\n",
       "      <td>-0.989710</td>\n",
       "      <td>-0.972868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.976739</td>\n",
       "      <td>-0.986867</td>\n",
       "      <td>-1.027213</td>\n",
       "      <td>-1.032271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.057451</td>\n",
       "      <td>-1.013304</td>\n",
       "      <td>-1.047258</td>\n",
       "      <td>-1.021294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.025166</td>\n",
       "      <td>-1.019107</td>\n",
       "      <td>-1.021394</td>\n",
       "      <td>-1.009026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.025166</td>\n",
       "      <td>-1.034060</td>\n",
       "      <td>-1.045964</td>\n",
       "      <td>-1.051641</td>\n",
       "      <td>-1.601562</td>\n",
       "      <td>-1.026632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39573</th>\n",
       "      <td>-1.217583</td>\n",
       "      <td>-1.225440</td>\n",
       "      <td>-1.215375</td>\n",
       "      <td>-1.216289</td>\n",
       "      <td>1.556466</td>\n",
       "      <td>-1.220105</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>-1.254636</td>\n",
       "      <td>-1.257028</td>\n",
       "      <td>-1.249399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39574</th>\n",
       "      <td>-1.216938</td>\n",
       "      <td>-1.220281</td>\n",
       "      <td>-1.214081</td>\n",
       "      <td>-1.215321</td>\n",
       "      <td>1.595960</td>\n",
       "      <td>-1.218061</td>\n",
       "      <td>0.424076</td>\n",
       "      <td>-1.251647</td>\n",
       "      <td>-1.252429</td>\n",
       "      <td>-1.248044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39575</th>\n",
       "      <td>-1.215001</td>\n",
       "      <td>-1.202873</td>\n",
       "      <td>-1.207615</td>\n",
       "      <td>-1.194336</td>\n",
       "      <td>2.075965</td>\n",
       "      <td>-1.209731</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>-1.247511</td>\n",
       "      <td>-1.244231</td>\n",
       "      <td>-1.248023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39576</th>\n",
       "      <td>-1.194661</td>\n",
       "      <td>-1.168699</td>\n",
       "      <td>-1.187570</td>\n",
       "      <td>-1.169516</td>\n",
       "      <td>2.262051</td>\n",
       "      <td>-1.195020</td>\n",
       "      <td>0.678735</td>\n",
       "      <td>-1.242295</td>\n",
       "      <td>-1.230995</td>\n",
       "      <td>-1.250923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39577</th>\n",
       "      <td>-1.169479</td>\n",
       "      <td>-1.167409</td>\n",
       "      <td>-1.168819</td>\n",
       "      <td>-1.157533</td>\n",
       "      <td>2.311736</td>\n",
       "      <td>-1.179992</td>\n",
       "      <td>0.835146</td>\n",
       "      <td>-1.236221</td>\n",
       "      <td>-1.217566</td>\n",
       "      <td>-1.252295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39160 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close     rsi_0     wma_0    macd_0  \\\n",
       "0     -0.923792 -0.931312 -0.989710 -0.972868       NaN       NaN       NaN   \n",
       "1     -0.976739 -0.986867 -1.027213 -1.032271       NaN       NaN       NaN   \n",
       "2     -1.057451 -1.013304 -1.047258 -1.021294       NaN       NaN       NaN   \n",
       "3     -1.025166 -1.019107 -1.021394 -1.009026       NaN       NaN       NaN   \n",
       "4     -1.025166 -1.034060 -1.045964 -1.051641 -1.601562 -1.026632       NaN   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39573 -1.217583 -1.225440 -1.215375 -1.216289  1.556466 -1.220105  0.385375   \n",
       "39574 -1.216938 -1.220281 -1.214081 -1.215321  1.595960 -1.218061  0.424076   \n",
       "39575 -1.215001 -1.202873 -1.207615 -1.194336  2.075965 -1.209731  0.522100   \n",
       "39576 -1.194661 -1.168699 -1.187570 -1.169516  2.262051 -1.195020  0.678735   \n",
       "39577 -1.169479 -1.167409 -1.168819 -1.157533  2.311736 -1.179992  0.835146   \n",
       "\n",
       "       bollinger_mavg_0  bollinger_hband_0  bollinger_lband_0  \n",
       "0                   NaN                NaN                NaN  \n",
       "1                   NaN                NaN                NaN  \n",
       "2                   NaN                NaN                NaN  \n",
       "3                   NaN                NaN                NaN  \n",
       "4                   NaN                NaN                NaN  \n",
       "...                 ...                ...                ...  \n",
       "39573         -1.254636          -1.257028          -1.249399  \n",
       "39574         -1.251647          -1.252429          -1.248044  \n",
       "39575         -1.247511          -1.244231          -1.248023  \n",
       "39576         -1.242295          -1.230995          -1.250923  \n",
       "39577         -1.236221          -1.217566          -1.252295  \n",
       "\n",
       "[39160 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcfa6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data_train.dropna(inplace=True)\n",
    "norm_data_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9cff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data_train to a CSV file\n",
    "norm_data_train.to_csv(\"data_train.csv\", index=False)\n",
    "\n",
    "# Export data_test to a CSV file\n",
    "norm_data_test.to_csv(\"data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ad0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data_train = pd.read_csv(\"data_train.csv\")\n",
    "\n",
    "norm_data_test = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2793a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lags):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Add original features with lags\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     X_train[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m norm_data_train\u001b[38;5;241m.\u001b[39mOpen\u001b[38;5;241m.\u001b[39mshift(lag)\n\u001b[0;32m      9\u001b[0m     X_train[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m norm_data_train\u001b[38;5;241m.\u001b[39mHigh\u001b[38;5;241m.\u001b[39mshift(lag)\n\u001b[0;32m     10\u001b[0m     X_train[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m norm_data_train\u001b[38;5;241m.\u001b[39mLow\u001b[38;5;241m.\u001b[39mshift(lag)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'norm_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "lags = 5\n",
    "\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "for lag in range(lags):\n",
    "    # Add original features with lags\n",
    "    X_train[f\"Close_{lag}\"] = norm_data_train.Close.shift(lag)\n",
    "    \n",
    "    X_test[f\"Close_{lag}\"] = norm_data_test.Close.shift(lag)\n",
    "\n",
    "    # Add indicator features with lags\n",
    "    for i in range(15): \n",
    "        X_train[f'rsi_{i}_{lag}'] = norm_data_train[f'rsi_{i}'].shift(lag)\n",
    "        X_train[f'macd_{i}_{lag}'] = norm_data_train[f'macd_{i}'].shift(lag)\n",
    "        X_train[f'bollinger_mavg_{i}_{lag}'] = norm_data_train[f'bollinger_mavg_{i}'].shift(lag)\n",
    "\n",
    "        X_test[f'rsi_{i}_{lag}'] = norm_data_test[f'rsi_{i}'].shift(lag)\n",
    "        X_test[f'macd_{i}_{lag}'] = norm_data_test[f'macd_{i}'].shift(lag)\n",
    "        X_test[f'bollinger_mavg_{i}_{lag}'] = norm_data_test[f'bollinger_mavg_{i}'].shift(lag)\n",
    "\n",
    "# Train\n",
    "Y_train = np.where(X_train.Close.shift(-5) > X_train.Close * 1.01, 1, \n",
    "          np.where(X_train.Close.shift(-5) < X_train.Close * 0.99, -1, 0))\n",
    "\n",
    "# Test\n",
    "Y_test = np.where(X_test.Close.shift(-5) > X_test.Close * 1.01, 1, \n",
    "         np.where(X_test.Close.shift(-5) < X_test.Close * 0.99, -1, 0))\n",
    "\n",
    "# Removing NaNs and the last value due to shifting\n",
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)\n",
    "X_train = X_train.iloc[:-1, :].values\n",
    "X_test = X_test.iloc[:-1, :].values\n",
    "\n",
    "Y_train = Y_train.iloc[lags:-1].values.reshape(-1, 1)\n",
    "Y_test = Y_test.iloc[lags:-1].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b2ff049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    38265\n",
      "1      810\n",
      "Name: count, dtype: int64\n",
      "0    19129\n",
      "1      210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Y_validate_train = pd.DataFrame(Y_train)\n",
    "Y_validate_test = pd.DataFrame(Y_test)\n",
    "\n",
    "print(Y_validate_train.value_counts())\n",
    "print(Y_validate_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857138b6",
   "metadata": {},
   "source": [
    "## Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f687f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.shape[1]\n",
    "\n",
    "X_train = X_train.reshape(-1, features, 1)\n",
    "X_test = X_test.reshape(-1, features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6b2c1",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0f2030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer(inputs, head_size, num_heads, dnn_dim):\n",
    "    # Stacking layers\n",
    "    l1 = tf.keras.layers.MultiHeadAttention(key_dim=head_size,\n",
    "                                            num_heads=num_heads,\n",
    "                                            dropout=0.2)(inputs, inputs)\n",
    "    l2 = tf.keras.layers.Dropout(0.2)(l1)\n",
    "    l3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(l2)\n",
    "    \n",
    "    res = l3 + inputs\n",
    "    \n",
    "    # Traditional DNN\n",
    "    l4 = tf.keras.layers.Conv1D(filters=4, kernel_size=1, activation=\"relu\")(res)\n",
    "    l5 = tf.keras.layers.Dropout(0.2)(l4)\n",
    "    l6 = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(l5)\n",
    "    l7 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(l6)\n",
    "    return l7 + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6af8c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Hyperparams\n",
    "head_size = 256\n",
    "num_heads = 4\n",
    "num_transformer_blocks = 4\n",
    "dnn_dim = 4\n",
    "units = 128\n",
    "\n",
    "\n",
    "# Defining input_shape as Input layer\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "# Creating our transformers based on the input layer\n",
    "transformer_layers = input_layer\n",
    "\n",
    "for _ in range(num_transformer_blocks):\n",
    "    # Stacking transformers\n",
    "    transformer_layers = create_transformer(inputs=transformer_layers,\n",
    "                                            head_size=head_size,\n",
    "                                            num_heads=num_heads,\n",
    "                                            dnn_dim=dnn_dim)\n",
    "\n",
    "# Adding global pooling\n",
    "pooling_layer = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_last\")\\\n",
    "                                                      (transformer_layers)\n",
    "\n",
    "# Adding MLP layers\n",
    "l1 = tf.keras.layers.Dense(units=128, activation=\"leaky_relu\")(pooling_layer)\n",
    "l2 = tf.keras.layers.Dropout(0.3)(l1)\n",
    "l3 = tf.keras.layers.Dense(units=128, activation=\"leaky_relu\")(l2)\n",
    "\n",
    "# Last layer, units = 2 for True and False values\n",
    "outputs = tf.keras.layers.Dense(units=2, activation=\"softmax\")(l3)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Model(inputs=input_layer,\n",
    "                       outputs=outputs,\n",
    "                       name=\"transformers_classification\")\n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "adam_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n",
    "#callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "#                                              patience=10,\n",
    "#                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "247c9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=[metric],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11bb281c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformers_classification\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 20, 1)]              0         []                            \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (M  (None, 20, 1)                7169      ['input_9[0][0]',             \n",
      " ultiHeadAttention)                                                  'input_9[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)        (None, 20, 1)                0         ['multi_head_attention_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_64 (La  (None, 20, 1)                2         ['dropout_72[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (T  (None, 20, 1)                0         ['layer_normalization_64[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'input_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_64 (Conv1D)          (None, 20, 4)                8         ['tf.__operators__.add_64[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)        (None, 20, 4)                0         ['conv1d_64[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_65 (Conv1D)          (None, 20, 1)                5         ['dropout_73[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_65 (La  (None, 20, 1)                2         ['conv1d_65[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (T  (None, 20, 1)                0         ['layer_normalization_65[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_64[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_33 (M  (None, 20, 1)                7169      ['tf.__operators__.add_65[0][0\n",
      " ultiHeadAttention)                                                 ]',                           \n",
      "                                                                     'tf.__operators__.add_65[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)        (None, 20, 1)                0         ['multi_head_attention_33[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_66 (La  (None, 20, 1)                2         ['dropout_74[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (T  (None, 20, 1)                0         ['layer_normalization_66[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_65[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_66 (Conv1D)          (None, 20, 4)                8         ['tf.__operators__.add_66[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)        (None, 20, 4)                0         ['conv1d_66[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_67 (Conv1D)          (None, 20, 1)                5         ['dropout_75[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_67 (La  (None, 20, 1)                2         ['conv1d_67[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (T  (None, 20, 1)                0         ['layer_normalization_67[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_66[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (M  (None, 20, 1)                7169      ['tf.__operators__.add_67[0][0\n",
      " ultiHeadAttention)                                                 ]',                           \n",
      "                                                                     'tf.__operators__.add_67[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)        (None, 20, 1)                0         ['multi_head_attention_34[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_68 (La  (None, 20, 1)                2         ['dropout_76[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (T  (None, 20, 1)                0         ['layer_normalization_68[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_67[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)          (None, 20, 4)                8         ['tf.__operators__.add_68[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_77 (Dropout)        (None, 20, 4)                0         ['conv1d_68[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)          (None, 20, 1)                5         ['dropout_77[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_69 (La  (None, 20, 1)                2         ['conv1d_69[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (T  (None, 20, 1)                0         ['layer_normalization_69[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_68[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_35 (M  (None, 20, 1)                7169      ['tf.__operators__.add_69[0][0\n",
      " ultiHeadAttention)                                                 ]',                           \n",
      "                                                                     'tf.__operators__.add_69[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)        (None, 20, 1)                0         ['multi_head_attention_35[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_70 (La  (None, 20, 1)                2         ['dropout_78[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (T  (None, 20, 1)                0         ['layer_normalization_70[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_69[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)          (None, 20, 4)                8         ['tf.__operators__.add_70[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)        (None, 20, 4)                0         ['conv1d_70[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)          (None, 20, 1)                5         ['dropout_79[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_71 (La  (None, 20, 1)                2         ['conv1d_71[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (T  (None, 20, 1)                0         ['layer_normalization_71[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_70[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8  (None, 1)                    0         ['tf.__operators__.add_71[0][0\n",
      "  (GlobalAveragePooling1D)                                          ]']                           \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 128)                  256       ['global_average_pooling1d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)        (None, 128)                  0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 128)                  16512     ['dropout_80[0][0]']          \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 2)                    258       ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45770 (178.79 KB)\n",
      "Trainable params: 45770 (178.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fdcfc8c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "612/612 [==============================] - 42s 66ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.7089\n",
      "Epoch 2/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5457 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 3/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5458 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 4/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5455 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 5/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5452 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 6/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 7/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7184\n",
      "Epoch 8/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 9/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 10/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 11/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 12/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 13/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 14/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 15/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 16/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7178\n",
      "Epoch 17/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5450 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 18/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 19/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 20/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 21/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 22/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 23/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 24/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 25/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 26/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5449 - sparse_categorical_accuracy: 0.7184\n",
      "Epoch 27/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 28/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 29/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 30/100\n",
      "612/612 [==============================] - 41s 68ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 31/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 32/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7184\n",
      "Epoch 33/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 34/100\n",
      "612/612 [==============================] - 42s 68ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 35/100\n",
      "612/612 [==============================] - 42s 68ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 36/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 37/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 38/100\n",
      "612/612 [==============================] - 40s 65ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 39/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 40/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 41/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 42/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 43/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 44/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 45/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7175\n",
      "Epoch 46/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5439 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 47/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 48/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7196\n",
      "Epoch 49/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 50/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 51/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 52/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 53/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7178\n",
      "Epoch 54/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 55/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 56/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 57/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 58/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 59/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 60/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 61/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 62/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 63/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 64/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7174\n",
      "Epoch 65/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7179\n",
      "Epoch 66/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 67/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 68/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 69/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7191\n",
      "Epoch 70/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 71/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7193\n",
      "Epoch 72/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 73/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 74/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 75/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 76/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 77/100\n",
      "612/612 [==============================] - 41s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7180\n",
      "Epoch 78/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 79/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7192\n",
      "Epoch 80/100\n",
      "612/612 [==============================] - 41s 67ms/step - loss: 0.5441 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 81/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5446 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 82/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 83/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7186\n",
      "Epoch 84/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 85/100\n",
      "612/612 [==============================] - 40s 65ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.7189\n",
      "Epoch 86/100\n",
      "612/612 [==============================] - 40s 65ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 87/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7183\n",
      "Epoch 88/100\n",
      "612/612 [==============================] - 40s 65ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7189\n",
      "Epoch 89/100\n",
      "612/612 [==============================] - 70s 114ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 90/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7187\n",
      "Epoch 91/100\n",
      "612/612 [==============================] - 339s 555ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7192\n",
      "Epoch 92/100\n",
      "612/612 [==============================] - 236s 386ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 93/100\n",
      "612/612 [==============================] - 40s 66ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7193\n",
      "Epoch 94/100\n",
      "612/612 [==============================] - 42s 69ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7197\n",
      "Epoch 95/100\n",
      "612/612 [==============================] - 45s 73ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7188\n",
      "Epoch 96/100\n",
      "612/612 [==============================] - 44s 72ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 97/100\n",
      "612/612 [==============================] - 44s 73ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7176\n",
      "Epoch 98/100\n",
      "612/612 [==============================] - 44s 72ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7182\n",
      "Epoch 99/100\n",
      "612/612 [==============================] - 44s 72ms/step - loss: 0.5443 - sparse_categorical_accuracy: 0.7190\n",
      "Epoch 100/100\n",
      "612/612 [==============================] - 44s 72ms/step - loss: 0.5442 - sparse_categorical_accuracy: 0.7186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0963d50>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    # callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c84f1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"transformer_classifier.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a39f33ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - 22s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92b2bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18598"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_hat_train.argmax(axis=1) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43dfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
